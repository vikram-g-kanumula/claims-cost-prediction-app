{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ“Š Exploratory Data Analysis (EDA)\n",
                "## Insurance Claims Cost Prediction\n",
                "\n",
                "**Objective**: Understand the training dataset to inform feature engineering and model selection for predicting `UltimateIncurredClaimCost`.\n",
                "\n",
                "---\n",
                "\n",
                "### Table of Contents\n",
                "1. [Data Loading & Overview](#1-data-loading--overview)\n",
                "2. [Missing Values Analysis](#2-missing-values-analysis)\n",
                "3. [Target Variable Analysis](#3-target-variable-analysis)\n",
                "4. [Numerical Features Distribution](#4-numerical-features-distribution)\n",
                "5. [Categorical Features Analysis](#5-categorical-features-analysis)\n",
                "6. [Correlation Analysis](#6-correlation-analysis)\n",
                "7. [Feature vs Target Relationships](#7-feature-vs-target-relationships)\n",
                "8. [Outlier Detection](#8-outlier-detection)\n",
                "9. [Key Insights & Recommendations](#9-key-insights--recommendations)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import Libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "sns.set_palette('viridis')\n",
                "\n",
                "# Display settings\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.float_format', '{:.2f}'.format)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Data Loading & Overview"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the training dataset\n",
                "df = pd.read_csv('data/train.csv')\n",
                "\n",
                "print(f\"Dataset Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
                "print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# First 5 rows\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data Types and Info\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistical Summary\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ’¡ Initial Observations\n",
                "- **ClaimNumber**: Unique identifier (should be dropped for modeling)\n",
                "- **Date columns**: `DateTimeOfAccident`, `DateReported` - potential for time-based features\n",
                "- **Target**: `UltimateIncurredClaimCost` - this is what we need to predict\n",
                "- **Categorical**: `Gender`, `MaritalStatus`, `PartTimeFullTime`\n",
                "- **Numerical**: `Age`, `WeeklyWages`, `InitialIncurredCalimsCost`, etc.\n",
                "- **Text**: `ClaimDescription` - potential for NLP features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Missing Values Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Missing values summary\n",
                "missing = df.isnull().sum()\n",
                "missing_pct = (missing / len(df)) * 100\n",
                "\n",
                "missing_df = pd.DataFrame({\n",
                "    'Missing Count': missing,\n",
                "    'Missing %': missing_pct\n",
                "}).sort_values('Missing %', ascending=False)\n",
                "\n",
                "missing_df[missing_df['Missing Count'] > 0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize missing values\n",
                "if missing_df[missing_df['Missing Count'] > 0].shape[0] > 0:\n",
                "    plt.figure(figsize=(10, 4))\n",
                "    missing_cols = missing_df[missing_df['Missing Count'] > 0]\n",
                "    sns.barplot(x=missing_cols.index, y='Missing %', data=missing_cols, color='coral')\n",
                "    plt.title('Missing Values by Column (%)', fontsize=14, fontweight='bold')\n",
                "    plt.xticks(rotation=45, ha='right')\n",
                "    plt.ylabel('Percentage Missing')\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"âœ… No missing values in the dataset!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Target Variable Analysis\n",
                "\n",
                "Understanding the distribution of `UltimateIncurredClaimCost` is critical for choosing the right model and loss function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target = 'UltimateIncurredClaimCost'\n",
                "\n",
                "print(\"Target Variable Statistics:\")\n",
                "print(df[target].describe())\n",
                "print(f\"\\nSkewness: {df[target].skew():.2f}\")\n",
                "print(f\"Kurtosis: {df[target].kurtosis():.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Raw Distribution\n",
                "axes[0].hist(df[target], bins=100, color='steelblue', edgecolor='white')\n",
                "axes[0].set_title('Distribution of Ultimate Incurred Claim Cost (Raw)', fontsize=12, fontweight='bold')\n",
                "axes[0].set_xlabel('Cost ($)')\n",
                "axes[0].set_ylabel('Frequency')\n",
                "axes[0].axvline(df[target].mean(), color='red', linestyle='--', label=f'Mean: ${df[target].mean():,.0f}')\n",
                "axes[0].axvline(df[target].median(), color='orange', linestyle='--', label=f'Median: ${df[target].median():,.0f}')\n",
                "axes[0].legend()\n",
                "\n",
                "# Log-Transformed Distribution\n",
                "log_target = np.log1p(df[target])\n",
                "axes[1].hist(log_target, bins=100, color='seagreen', edgecolor='white')\n",
                "axes[1].set_title('Distribution of log(1 + Cost)', fontsize=12, fontweight='bold')\n",
                "axes[1].set_xlabel('Log-Transformed Cost')\n",
                "axes[1].set_ylabel('Frequency')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ’¡ Target Insights\n",
                "- **Extreme Right Skew**: The raw distribution shows a heavy right tail with most claims being low value.\n",
                "- **Log Transformation Helps**: The log-transformed distribution is much more normal-like.\n",
                "- **Recommendation**: Use `log1p(target)` for training and `expm1(prediction)` for inference."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Numerical Features Distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "numerical_cols = ['Age', 'WeeklyWages', 'InitialIncurredCalimsCost', \n",
                "                  'HoursWorkedPerWeek', 'DaysWorkedPerWeek', \n",
                "                  'DependentChildren', 'DependentsOther']\n",
                "\n",
                "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i, col in enumerate(numerical_cols):\n",
                "    if col in df.columns:\n",
                "        axes[i].hist(df[col].dropna(), bins=50, color='steelblue', edgecolor='white')\n",
                "        axes[i].set_title(f'Distribution of {col}', fontsize=11, fontweight='bold')\n",
                "        axes[i].set_xlabel(col)\n",
                "        axes[i].set_ylabel('Frequency')\n",
                "\n",
                "# Hide unused subplots\n",
                "for j in range(len(numerical_cols), len(axes)):\n",
                "    axes[j].axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ’¡ Numerical Feature Observations\n",
                "- **Age**: Relatively uniform distribution, typical working age range.\n",
                "- **WeeklyWages**: Right-skewed with some high earners.\n",
                "- **InitialIncurredClaimsCost**: Highly skewed, similar to the target (expected correlation).\n",
                "- **DependentChildren/DependentsOther**: Mostly low values (0-2)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Categorical Features Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "categorical_cols = ['Gender', 'MaritalStatus', 'PartTimeFullTime']\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "for i, col in enumerate(categorical_cols):\n",
                "    if col in df.columns:\n",
                "        value_counts = df[col].value_counts()\n",
                "        axes[i].bar(value_counts.index, value_counts.values, color='teal', edgecolor='white')\n",
                "        axes[i].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
                "        axes[i].set_xlabel(col)\n",
                "        axes[i].set_ylabel('Count')\n",
                "        \n",
                "        # Add percentage labels\n",
                "        for idx, (cat, count) in enumerate(zip(value_counts.index, value_counts.values)):\n",
                "            pct = count / len(df) * 100\n",
                "            axes[i].text(idx, count + len(df)*0.01, f'{pct:.1f}%', ha='center', fontsize=9)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Categorical vs Target (Box plots)\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "for i, col in enumerate(categorical_cols):\n",
                "    if col in df.columns:\n",
                "        df.boxplot(column=target, by=col, ax=axes[i])\n",
                "        axes[i].set_title(f'{col} vs {target}', fontsize=12, fontweight='bold')\n",
                "        axes[i].set_xlabel(col)\n",
                "        axes[i].set_ylabel('Claim Cost ($)')\n",
                "        axes[i].set_ylim(0, df[target].quantile(0.95))  # Focus on 95th percentile\n",
                "\n",
                "plt.suptitle('')  # Remove default title\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ’¡ Categorical Insights\n",
                "- **Gender**: Imbalanced (more males, typical in workers' comp data).\n",
                "- **MaritalStatus**: Married (M) is the largest group.\n",
                "- **PartTimeFullTime**: Full-time workers dominate."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Correlation Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute correlation matrix for numerical columns\n",
                "corr_cols = numerical_cols + [target]\n",
                "corr_matrix = df[corr_cols].corr()\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
                "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r', \n",
                "            center=0, linewidths=0.5, square=True)\n",
                "plt.title('Correlation Matrix (Numerical Features)', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation with Target\n",
                "target_corr = corr_matrix[target].drop(target).sort_values(ascending=False)\n",
                "\n",
                "plt.figure(figsize=(8, 5))\n",
                "colors = ['green' if x > 0 else 'red' for x in target_corr.values]\n",
                "plt.barh(target_corr.index, target_corr.values, color=colors)\n",
                "plt.xlabel('Correlation Coefficient')\n",
                "plt.title('Feature Correlation with Target', fontsize=14, fontweight='bold')\n",
                "plt.axvline(0, color='black', linewidth=0.5)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ’¡ Correlation Insights\n",
                "- **InitialIncurredClaimsCost**: Strong positive correlation with target (expected - initial estimate drives final cost).\n",
                "- **WeeklyWages**: Moderate positive correlation (higher wages â†’ higher claims?).\n",
                "- Other features have weak correlations, suggesting non-linear relationships or feature engineering opportunities."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. Feature vs Target Relationships"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scatter plots for key features vs target\n",
                "key_features = ['InitialIncurredCalimsCost', 'WeeklyWages', 'Age']\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "for i, col in enumerate(key_features):\n",
                "    axes[i].scatter(df[col], df[target], alpha=0.3, s=10, color='steelblue')\n",
                "    axes[i].set_xlabel(col)\n",
                "    axes[i].set_ylabel(target)\n",
                "    axes[i].set_title(f'{col} vs Target', fontsize=12, fontweight='bold')\n",
                "    axes[i].set_ylim(0, df[target].quantile(0.99))\n",
                "    \n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 8. Outlier Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Box plots for outlier detection\n",
                "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
                "axes = axes.flatten()\n",
                "\n",
                "all_numeric = numerical_cols + [target]\n",
                "\n",
                "for i, col in enumerate(all_numeric):\n",
                "    if col in df.columns and i < len(axes):\n",
                "        axes[i].boxplot(df[col].dropna(), vert=True)\n",
                "        axes[i].set_title(f'{col}', fontsize=11, fontweight='bold')\n",
                "        axes[i].set_ylabel('Value')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quantile analysis for target\n",
                "print(\"Target Variable Percentiles:\")\n",
                "for q in [0.25, 0.50, 0.75, 0.90, 0.95, 0.99, 1.0]:\n",
                "    val = df[target].quantile(q)\n",
                "    print(f\"  {int(q*100):3d}th percentile: ${val:,.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ’¡ Outlier Observations\n",
                "- **Target**: Top 1% of claims have extremely high values (long tail).\n",
                "- **InitialIncurredClaimsCost**: Similar pattern to target.\n",
                "- **Consideration**: Tree-based models are robust to outliers, but log-transformation helps with gradient descent methods."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 9. Key Insights & Recommendations\n",
                "\n",
                "### ðŸ“Œ Summary of Findings\n",
                "\n",
                "| Aspect | Finding | Implication |\n",
                "|--------|---------|-------------|\n",
                "| **Target Distribution** | Highly right-skewed | Use `log1p` transformation for training |\n",
                "| **Key Predictor** | `InitialIncurredClaimsCost` | Strong correlation with target, most important feature |\n",
                "| **Missing Values** | Minimal/None | No complex imputation needed |\n",
                "| **Categorical Features** | Imbalanced classes | Use label encoding; tree models handle this well |\n",
                "| **Text Feature** | `ClaimDescription` available | Use TF-IDF + SVD for dimensionality reduction |\n",
                "| **Date Features** | Accident and Report dates | Engineer `ReportLag`, `AccidentYear`, `AccidentMonth`, `DayOfWeek` |\n",
                "\n",
                "### ðŸŽ¯ Recommended Feature Engineering\n",
                "1. **Date Features**: `ReportLag = DateReported - DateTimeOfAccident`\n",
                "2. **Log Transform**: `LogInitialCost = log1p(InitialIncurredClaimsCost)`\n",
                "3. **Interaction**: `Age_Wage_Interaction = Age * WeeklyWages`\n",
                "4. **NLP Features**: TF-IDF (1000 features) + TruncatedSVD (30 components) on `ClaimDescription`\n",
                "\n",
                "### ðŸ§  Model Recommendations\n",
                "- **Primary**: Gradient Boosting (XGBoost, LightGBM) - handles skewed data, non-linear relationships\n",
                "- **Ensemble**: Stacking with Ridge meta-learner for robust predictions\n",
                "- **Evaluation**: RMSE on original scale (after `expm1` transformation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nâœ… EDA Complete!\")\n",
                "print(\"Proceed to feature engineering and model training.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}